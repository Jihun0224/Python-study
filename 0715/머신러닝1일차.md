### ë°ì´í„° ì „ì²˜ë¦¬  
ë³€ìˆ˜ ë³€í™˜  
ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§  
ë³€ìˆ˜ ì¶”ì¶œ  
ë³€ìˆ˜ ì„ íƒ  
ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í¬ê²Œ ì¢Œìš°  

### DataFrame ìƒí˜¸ ë³€í™˜  
ndarray, ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬ -> DataFrame ìƒì„±: 2ì°¨ì› í–‰,ì—´ ì´í•˜, ì»¬ëŸ¼ëª… ì§€ì •  
df.values() -> ndarray ë°˜í™˜  
df.values.tolist() -> ë¦¬ìŠ¤íŠ¸ ë°˜í™˜  
df.to_dict() -> ë”•ì…”ë„ˆë¦¬ ë°˜í™˜  

### one-hot-encoding ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë²”ì£¼í™”  
â€œThe cat in the hat.â€ -> [â€˜theâ€™, â€˜catâ€™, â€˜inâ€™, â€˜theâ€™, â€˜hatâ€™, â€˜<EOS>â€™]  
<EOS>: end of sentence  

### numpyì™€ tensorì˜ ì°¨ì´  
1. í…ì„œëŠ” GPU, TPUì™€ ê°™ì€ ê°€ì†ê¸° ë©”ëª¨ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥  
2. í…ì„œëŠ” ë¶ˆë³€ì„±ì„ ê°€ì§ -> ìƒì„± ì´í›„ ë³€ê²½ì´ ë¶ˆê°€ëŠ¥í•œ ê°ì²´  

### What is Machine Learning  
Machine Learning allows computers to learn and infer(ì¶”ë¡ v) from data.  
### AI Definitions
![image](https://user-images.githubusercontent.com/59672592/125727866-519ee11d-a0dc-4e81-b87b-1d4f8c759568.png)  

### Machine Learning & Deep Learning  
* Classic Machine Learning  
Step 1: Determine features.  
Step 2: Feedthem through model.  
* Deep Learning  
Steps 1 and 2 are combined into 1 step.  

### Data Structure for Machine Learning  
ë²¡í„°(1D) -> ì‹œë¦¬ì¦ˆ(Series)  
ë°°ì—´(2D) -> ë°ì´í„°í”„ë ˆì„(DataFrame)  
### Types of Machine Learning  
ì§€ë„í•™ìŠµ(Supervised): íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ê°€ì§€ê³  ìˆê³ , ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨.ex)Fraud detection  
ë¹„ì§€ë„ í•™ìŠµ(unSupervised): íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì •í•´ì ¸ ìˆì§€ ì•Šê³ , ë°ì´í„° êµ¬ì¡°ë¥¼ ì°¾ëŠ”ê²ƒì„ ëª©í‘œë¡œ í•¨. ex) Customer segmentation  

### Machine Learning Vocabulary  
* Target: Response, Output, Dependent Variable, Labels  
* Features: Predictors, Input, Independent Variables,
Attributes  
* Example: Observation, Record, Instance, Datapoint, Row  
* Label: Answer, y-value, Category, Target  
![image](https://user-images.githubusercontent.com/59672592/125729274-ed066486-134f-4bf9-b897-3dcbf86390ed.png)  

### ì§€ë„ í•™ìŠµ Overview  
Data with answers + Model -- Fit --> <span style="color:green
">Model</span>  
Data without answers + <span style="color:green
">Model</span>-- Predict --> Predict answers  
### Regression: Numerical Answers  
Movie data with revenue + Model -- Fit --> <span style="color:green
">Model</span>  
Movie data(unknown revenue) + <span style="color:green
">Model</span>-- Predict --> Predict revenue  
### Classification: Categorical Answers  
Labeled data + Model -- Fit --> <span style="color:green
">Model</span>  
Unlabeled data + <span style="color:green
">Model</span>-- Predict --> Labels  
### Classification: Categorical Answers  
Emails labeled as spam/not spam + Model -- Fit --> <span style="color:blue">Model</span>  
Unlabeled emails + <span style="color:blue
">Model</span>-- Predict --> Spam or not spam  

### Supervised Learning ì•Œê³ ë¦¬ì¦˜  
1. Linear Regression  
- Polynomial Regression  
- Stepwise Linear Regression  
- Lasso, Ridge  
2. Logistic Regression  
3. K-Nearest Neighbors  
4. Naive Bayes Classifier  
5. Decision Tree  
6. Random Forest  
### Un-Supervised Learning ì•Œê³ ë¦¬ì¦˜  
1. Clustering  
- K-mean Clustering  
- (Agglomerative) Hierarchical Clustering  
- DBSCAN  
- Gaussian mixture model  
- Self-organizing map(SOM)  
### Machine Learning í•µì‹¬ Factor  
1. Loss function (Cost function)  
2. Parameter, Hyperparameter  
Hyperparameter: ì‚¬ëŒì´ ì§ì ‘ ë°ì´í„° ê°’ì„ ë³€í™”ì‹œí‚¤ë©´ì„œ í•™ìŠµì— ë°˜ì˜ ì‹œì¼œ ë‚˜ì˜¤ëŠ” ê²°ê³¼ë¬¼  
parameter: ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ ë°ì´í„°ë¥¼ í†µí•´ì„œ ë‚˜ì˜¤ëŠ” ê²°ê³¼ë¬¼  
3. Regression Performance measure  
- MSE, MAE, RMSE, R-square  
4. Classification Performance  
- Confusion matrix, f1-score, AUC/ROC  
5. Bias-Variance trade-off  
- Overfitting, Underfitting  
6. Bootstrap aggregating(Bagging)  
## 1.Importing and Understanding Data  
```python
DF.head()
DF.tail()  
DF.info()  
DF.describe()  
DF.columns  
```
## 2.Visualising Data  
```python
import matplotlib.pyplot as plt  
import seaborn as sns  
sns.pairplot(DF)  
# the featuresì™€ responseì˜ ê´€ê³„ë¥¼ scatterplotìœ¼ë¡œ ê·¸ë¦¬ê¸°  
sns.pairplot(advertising_multi, x_vars=['TV','Radio','Newspaper'], y_vars='Sales' , size=7, aspect=0.7, kind='scatter')  
```

## 3.Splitting Train/Test set  
```python
X = DF[['x1','x2','x3']]  
y = DF['y']  
from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 , random_state=100)  
# random_state ===> ê°™ì€ ìˆ˜ë¥¼ ë„£ìœ¼ë©´ ë™ì¼í•˜ê²Œ set splití•œ data ì‚¬ìš© ê°€ëŠ¥ 
```
## *Fitting Training and Test Data  
![image](https://user-images.githubusercontent.com/59672592/125733702-c34e7421-4e0c-4f90-9117-56ba983f5a62.png)  
ì˜¤ì°¨ê°’ ê²€ì¦ì„ ìœ„í•´ traingin dataì™€ test dataë¡œ ë¶„ë¦¬  
## 4.Performing Linear Regression  
```python
from sklearn.linear_model import LinearRegression
lm = LinearRegression()
lm.fit(X_train,y_train)
```
## *Simple Linear Regression ê³µì‹  
ğ‘¦=ğ‘+ğ‘š1ğ‘¥1+ğ‘š2ğ‘¥2+...+ğ‘šğ‘›ğ‘¥ğ‘›  
ğ‘¦ is the response (y target)  
ğ‘ is the intercept (ì ˆí¸)  
ğ‘š1 is the coefficient for the first feature (1ì°¨ ìƒê´€ê³„ìˆ˜)  
ğ‘šğ‘› is the coefficient for the nth feature (nì°¨ ìƒê´€ê³„ìˆ˜)  
Linear Regressionì„ ìœ„í•´ seabornì˜ scatterë¥¼ ë§ì´ ì‚¬ìš©  
## -Linear Regression ëª¨ë¸ë§  
from sklearn.linear_model import LinearRegression  
#lrì— LinearRegression() ì§€ì •  
lr = LinearRegression()  
#lr.fit() Model Fit í•˜ê¸°  
lr.fit(X_train, y_train)  
## *ìµœì†Œì œê³±ë²•ìœ¼ë¡œ íšŒê·€ì„  êµ¬í•˜ê¸°  
1. X, Yì˜ í‰ê· ì„ êµ¬í•©ë‹ˆë‹¤.  
2. ìµœì†Œì œê³±ë²•ìœ¼ë¡œ a, bë¥¼ êµ¬í•©ë‹ˆë‹¤.  
3. ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ íšŒê·€ì„ ì˜ x, y ë°ì´í„°ë¥¼ êµ¬í•©ë‹ˆë‹¤.  
+ ì´ë¯¸ sklearnì— êµ¬í˜„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë¶ˆëŸ¬ì™€ì„œ ì“°ë©´ ë¨  
## 5.Model Evaluation  
```python
# print the intercept(ì ˆí¸)
print(lm.intercept_)
#coefficient(ìƒê´€ê³„ìˆ˜)
lm.coef_
coeff_df = pd.DataFrame(lm.coef_, X_test.columns,columns=['Coefficient'])
```
+ Preparing X and y  
scikit-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ X (feature variable)ì™€ y (response variable)ë¥¼ NumPy ë°°ì—´(arrays)ë¡œ êµ¬ì¶•  
X, yë¥¼ pands ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì „í™˜í•œë‹¤, pandasëŠ” NumPyì˜ array ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ì‰½ê²Œ ì „í™˜  
ex)íšŒê·€ì‹: y = 2.652 + 0.045426 x TV + 0.189758 x Radio + 0.004603 x Newspaper  
ìœ„ì˜ ê²°ê³¼ë¡œ TV marketing priceê°€ ì¦ê°€í•  ìˆ˜ë¡ sales ë§¤ì¶œì€ 0.045ëŒ€ì”© ì¦ê°€í•œë‹¤ëŠ” ê²ƒì„ ì˜ˆì¸¡ ê°€ëŠ¥  
## 6.Predictions  
```python
y_pred = lm.predict(X_test) 
```

## 7.Evaluation RMSE, R^2 Values  
![image](https://user-images.githubusercontent.com/59672592/125737596-9d20ba47-4e80-47d3-bd0a-7d6cfc82f6b3.png)  
Scikit learnì—ì„œ metrics ë¶ˆëŸ¬ì˜¤ê¸°  
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error
mae = mean_absolute_error(y_test, y_pred)  
mse = mean_squared_error(y_test, y_pred)  
r_squared = r2_score(y_test, y_pred) 
print('Mean_Absolute_Error:', mae)
print('Mean_Squared_Error :' ,mse)
print('R_Square_value :',r_squared) 
```
