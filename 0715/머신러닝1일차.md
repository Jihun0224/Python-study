### 데이터 전처리  
변수 변환  
변수 스케일링  
변수 추출  
변수 선택  
데이터 분석 결과를 크게 좌우  

### DataFrame 상호 변환  
ndarray, 리스트, 딕셔너리 -> DataFrame 생성: 2차원 행,열 이하, 컬럼명 지정  
df.values() -> ndarray 반환  
df.values.tolist() -> 리스트 반환  
df.to_dict() -> 딕셔너리 반환  

### one-hot-encoding 으로 카테고리 범주화  
“The cat in the hat.” -> [‘the’, ‘cat’, ‘in’, ‘the’, ‘hat’, ‘<EOS>’]  
<EOS>: end of sentence  

### numpy와 tensor의 차이  
1. 텐서는 GPU, TPU와 같은 가속기 메모리에서 사용 가능  
2. 텐서는 불변성을 가짐 -> 생성 이후 변경이 불가능한 객체  

### What is Machine Learning  
Machine Learning allows computers to learn and infer(추론v) from data.  
### AI Definitions
![image](https://user-images.githubusercontent.com/59672592/125727866-519ee11d-a0dc-4e81-b87b-1d4f8c759568.png)  

### Machine Learning & Deep Learning  
* Classic Machine Learning  
Step 1: Determine features.  
Step 2: Feedthem through model.  
* Deep Learning  
Steps 1 and 2 are combined into 1 step.  

### Data Structure for Machine Learning  
벡터(1D) -> 시리즈(Series)  
배열(2D) -> 데이터프레임(DataFrame)  
### Types of Machine Learning  
지도학습(Supervised): 타겟 컬럼을 가지고 있고, 예측하는 것을 목표로 함.ex)Fraud detection  
비지도 학습(unSupervised): 타겟 컬럼이 정해져 있지 않고, 데이터 구조를 찾는것을 목표로 함. ex) Customer segmentation  

### Machine Learning Vocabulary  
* Target: Response, Output, Dependent Variable, Labels  
* Features: Predictors, Input, Independent Variables,
Attributes  
* Example: Observation, Record, Instance, Datapoint, Row  
* Label: Answer, y-value, Category, Target  
![image](https://user-images.githubusercontent.com/59672592/125729274-ed066486-134f-4bf9-b897-3dcbf86390ed.png)  

### 지도 학습 Overview  
Data with answers + Model -- Fit --> <span style="color:green
">Model</span>  
Data without answers + <span style="color:green
">Model</span>-- Predict --> Predict answers  
### Regression: Numerical Answers  
Movie data with revenue + Model -- Fit --> <span style="color:green
">Model</span>  
Movie data(unknown revenue) + <span style="color:green
">Model</span>-- Predict --> Predict revenue  
### Classification: Categorical Answers  
Labeled data + Model -- Fit --> <span style="color:green
">Model</span>  
Unlabeled data + <span style="color:green
">Model</span>-- Predict --> Labels  
### Classification: Categorical Answers  
Emails labeled as spam/not spam + Model -- Fit --> <span style="color:blue">Model</span>  
Unlabeled emails + <span style="color:blue
">Model</span>-- Predict --> Spam or not spam  

### Supervised Learning 알고리즘  
1. Linear Regression  
- Polynomial Regression  
- Stepwise Linear Regression  
- Lasso, Ridge  
2. Logistic Regression  
3. K-Nearest Neighbors  
4. Naive Bayes Classifier  
5. Decision Tree  
6. Random Forest  
### Un-Supervised Learning 알고리즘  
1. Clustering  
- K-mean Clustering  
- (Agglomerative) Hierarchical Clustering  
- DBSCAN  
- Gaussian mixture model  
- Self-organizing map(SOM)  
### Machine Learning 핵심 Factor  
1. Loss function (Cost function)  
2. Parameter, Hyperparameter  
Hyperparameter: 사람이 직접 데이터 값을 변화시키면서 학습에 반영 시켜 나오는 결과물  
parameter: 데이터를 학습시킬 때 데이터를 통해서 나오는 결과물  
3. Regression Performance measure  
- MSE, MAE, RMSE, R-square  
4. Classification Performance  
- Confusion matrix, f1-score, AUC/ROC  
5. Bias-Variance trade-off  
- Overfitting, Underfitting  
6. Bootstrap aggregating(Bagging)  
## 1.Importing and Understanding Data  
```python
DF.head()
DF.tail()  
DF.info()  
DF.describe()  
DF.columns  
```
## 2.Visualising Data  
```python
import matplotlib.pyplot as plt  
import seaborn as sns  
sns.pairplot(DF)  
# the features와 response의 관계를 scatterplot으로 그리기  
sns.pairplot(advertising_multi, x_vars=['TV','Radio','Newspaper'], y_vars='Sales' , size=7, aspect=0.7, kind='scatter')  
```

## 3.Splitting Train/Test set  
```python
X = DF[['x1','x2','x3']]  
y = DF['y']  
from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 , random_state=100)  
# random_state ===> 같은 수를 넣으면 동일하게 set split한 data 사용 가능 
```
## *Fitting Training and Test Data  
![image](https://user-images.githubusercontent.com/59672592/125733702-c34e7421-4e0c-4f90-9117-56ba983f5a62.png)  
오차값 검증을 위해 traingin data와 test data로 분리  
## 4.Performing Linear Regression  
```python
from sklearn.linear_model import LinearRegression
lm = LinearRegression()
lm.fit(X_train,y_train)
```
## *Simple Linear Regression 공식  
𝑦=𝑐+𝑚1𝑥1+𝑚2𝑥2+...+𝑚𝑛𝑥𝑛  
𝑦 is the response (y target)  
𝑐 is the intercept (절편)  
𝑚1 is the coefficient for the first feature (1차 상관계수)  
𝑚𝑛 is the coefficient for the nth feature (n차 상관계수)  
Linear Regression을 위해 seaborn의 scatter를 많이 사용  
## -Linear Regression 모델링  
from sklearn.linear_model import LinearRegression  
#lr에 LinearRegression() 지정  
lr = LinearRegression()  
#lr.fit() Model Fit 하기  
lr.fit(X_train, y_train)  
## *최소제곱법으로 회귀선 구하기  
1. X, Y의 평균을 구합니다.  
2. 최소제곱법으로 a, b를 구합니다.  
3. 그래프를 그리기 위해 회귀선의 x, y 데이터를 구합니다.  
+ 이미 sklearn에 구현되어 있으므로 불러와서 쓰면 됨  
## 5.Model Evaluation  
```python
# print the intercept(절편)
print(lm.intercept_)
#coefficient(상관계수)
lm.coef_
coeff_df = pd.DataFrame(lm.coef_, X_test.columns,columns=['Coefficient'])
```
+ Preparing X and y  
scikit-learn 라이브러리를 사용하려면 X (feature variable)와 y (response variable)를 NumPy 배열(arrays)로 구축  
X, y를 pands 데이터프레임으로 전환한다, pandas는 NumPy의 array 기반으로 데이터프레임 쉽게 전환  
ex)회귀식: y = 2.652 + 0.045426 x TV + 0.189758 x Radio + 0.004603 x Newspaper  
위의 결과로 TV marketing price가 증가할 수록 sales 매출은 0.045대씩 증가한다는 것을 예측 가능  
## 6.Predictions  
```python
y_pred = lm.predict(X_test) 
```

## 7.Evaluation RMSE, R^2 Values  
![image](https://user-images.githubusercontent.com/59672592/125737596-9d20ba47-4e80-47d3-bd0a-7d6cfc82f6b3.png)  
Scikit learn에서 metrics 불러오기  
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error
mae = mean_absolute_error(y_test, y_pred)  
mse = mean_squared_error(y_test, y_pred)  
r_squared = r2_score(y_test, y_pred) 
print('Mean_Absolute_Error:', mae)
print('Mean_Squared_Error :' ,mse)
print('R_Square_value :',r_squared) 
```
