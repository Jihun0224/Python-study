{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "   이 크롤러는 인스타그램의 해시태그 정보를 수집합니다\n",
      "   본 제품은 서진수가 교육용으로 특별 제작했으며 \n",
      "   용도외의 사용으로 저작권을 침해하는 행위는 불법입니다\n",
      "   본 제품에 대한 문의는 seojinsu@gmail.com 으로 보내주세요~^^\n",
      "======================================================================\n",
      "1.인스타그램의 ID를 입력하세요: jihun__97\n",
      "2.인스타그램의 비밀번호를 입력하세요: djaakwkd1@\n",
      "3.검색할 해쉬태그를 입력하세요(예: 강남맛집): 강남맛집\n",
      "4.크롤링 할 건수는 몇건입니까?: 15\n",
      "5.파일이 저장될 경로만 쓰세요(기본경로 : c:\\temp\\ ) : \n",
      "\n",
      "\n",
      "요청하신 데이터를 추출중이오니 잠시만 기다려 주세요~~~~^^\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div[2]/div/a[1]/div\"}\n  (Session info: chrome=91.0.4472.124)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-17eb7540dad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div[2]/div/a[1]/div'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# 자동 스크롤다운 함수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div[2]/div/a[1]/div\"}\n  (Session info: chrome=91.0.4472.124)\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# 인스타 그램의 해쉬태그 수집하기 - by 서진수\n",
    "##########################################################################\n",
    "#Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import unicodedata   # 인스타그램의 해시태그 수집 중 자음/모음 분리현상 방지용 모듈\n",
    "\n",
    "#Step 2. 사용자에게 필요한 정보들을를 입력 받습니다.\n",
    "print(\"=\" *70)\n",
    "print(\"   이 크롤러는 인스타그램의 해시태그 정보를 수집합니다\")\n",
    "print(\"   본 제품은 서진수가 교육용으로 특별 제작했으며 \")\n",
    "print(\"   용도외의 사용으로 저작권을 침해하는 행위는 불법입니다\")\n",
    "print(\"   본 제품에 대한 문의는 seojinsu@gmail.com 으로 보내주세요~^^\")\n",
    "print(\"=\" *70)\n",
    "\n",
    "v_id = input(\"1.인스타그램의 ID를 입력하세요: \")\n",
    "v_passwd = input(\"2.인스타그램의 비밀번호를 입력하세요: \")\n",
    "query_txt = input(\"3.검색할 해쉬태그를 입력하세요(예: 강남맛집): \")\n",
    "cnt = int(input('4.크롤링 할 건수는 몇건입니까?: '))\n",
    "real_cnt = math.ceil(cnt / 30)\n",
    "\n",
    "f_dir=input('5.파일이 저장될 경로만 쓰세요(기본경로 : c:\\\\temp\\\\ ) : ')\n",
    "if f_dir =='' :\n",
    "    f_dir = \"c:\\\\temp\\\\\"\n",
    "\n",
    "#Step 3. 결과를 저장할 폴더명과 파일명을 설정하고 폴더를 생성합니다.\n",
    "s_time = time.time( )\n",
    "query_txt2 = '인스타그램'\n",
    "\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s+'-'+query_txt2+'-'+query_txt)\n",
    "f_name=f_dir+s+'-'+query_txt2+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.txt'\n",
    "\n",
    "# Step 4. 인스타그램 자동 로그인 하기\n",
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "driver.get(\"https://www.instagram.com/\")\n",
    "time.sleep(random.randrange(1,5))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"요청하신 데이터를 추출중이오니 잠시만 기다려 주세요~~~~^^\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#ID와 비번 입력후 로그인하기\n",
    "eid = driver.find_element_by_name('username')\n",
    "for a in v_id :\n",
    "        eid.send_keys(a)\n",
    "        time.sleep(0.3)\n",
    "epwd = driver.find_element_by_name('password')\n",
    "for b in v_passwd :\n",
    "        epwd.send_keys(b)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]/button/div').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Step 5. 검색할 해쉬태그 입력하기\n",
    "#로그인 정보 나중에 저장하기\n",
    "driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/div/div/button').click()\n",
    "time.sleep(2)\n",
    "#알림 설정 나중에 하기\n",
    "driver.find_element_by_xpath('/html/body/div[4]/div/div/div/div[3]/button[2]').click()\n",
    "time.sleep(1)\n",
    "\n",
    "# 검색할 키워드 입력하기\n",
    "element = driver.find_element_by_xpath('''//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input''')\n",
    "\n",
    "for c in query_txt :\n",
    "    element.send_keys(c)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]').click()\n",
    "\n",
    "# 자동 스크롤다운 함수\n",
    "def scroll_down(driver):\n",
    "  driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "  time.sleep(5)\n",
    "\n",
    "i = 1\n",
    "while (i <= real_cnt):\n",
    "      scroll_down(driver) \n",
    "      i += 1\n",
    "\n",
    "# Step 6. 전체 게시물의 원본 URL 추출하기\n",
    "item=[]\n",
    "count = 0\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "all = soup.find('article','KC1QD').find_all('a')\n",
    "\n",
    "for i in all:    \n",
    "    url = i['href']\n",
    "    item.append(url)  \n",
    "    count += 1\n",
    "    \n",
    "    if count == cnt :\n",
    "        break\n",
    "\n",
    "# 추출된 URL 사용하여 전체 URL 완성하기\n",
    "full_url=[]\n",
    "url_cnt = 0\n",
    "for x in range(0,len(item)) :\n",
    "    url_cnt += 1\n",
    "    url = 'https://www.instagram.com' +item[x]\n",
    "    full_url.append(url)\n",
    "\n",
    "#Step 7. 각 페이지별로 그림과 해쉬태그를 수집하기\n",
    "count = 1        # 추출 데이터 건수 세기\n",
    "hash_txt = []    # 해쉬 태그 저장 \n",
    "\n",
    "# 비트맵 이미지 아이콘을 위한 대체 딕셔너리를 만든다\n",
    "import sys\n",
    "bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "\n",
    "count = 0\n",
    "for c in range(0,len(full_url)) :\n",
    "    driver.get(full_url[c])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    f = open(f_name, 'a',encoding='UTF-8')\n",
    "        \n",
    "    # 해당 페이지의 해시태그 수집\n",
    "    tags = soup.find('div','EtaWk')\n",
    "    \n",
    "    try :\n",
    "        tags_1 = tags.find_all('a')\n",
    "    except :\n",
    "        pass\n",
    "    else :\n",
    "        for d in range(0, len(tags_1)) :\n",
    "            tags = tags_1[d].get_text()\n",
    "            tags_11 = tags.translate(bmp_map)\n",
    "            tags_2 = unicodedata.normalize('NFC', tags_11)\n",
    "            \n",
    "            for i in tags_2 :\n",
    "                if i[0:1]=='#' :\n",
    "                    hash_txt.append(tags_2)\n",
    "                    print(tags_2)\n",
    "                    f.write(\"\\n\" + str(tags_2))\n",
    "    f.close()\n",
    "    count += 1\n",
    "    \n",
    "#Step 7. 요약 정보 출력하기    \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *100)\n",
    "print(\"총 소요시간: %s 초\" %round(t_time,1))\n",
    "print(\"총 저장 건수: %s 건 \" %count)\n",
    "print(\"파일 저장 경로: %s\" %f_name)\n",
    "print(\"=\" *100)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#막국수\n",
      "#송림면옥\n",
      "#비빔막국수\n",
      "#물막국수\n",
      "#백숙찜닭\n",
      "#죽\n",
      "#도가니닭곰탕\n",
      "#김치맛집\n",
      "#초계탕\n",
      "#갈비찜\n",
      "#서울\n",
      "#서울맛집\n",
      "#강남\n",
      "#강남맛집\n",
      "#역삼동\n",
      "#역삼동맛집\n",
      "#역삼역맛집\n",
      "#먜슐랭\n",
      "#먜슐랭_강남\n",
      "#먜슐랭_역삼동\n",
      "#문썬과함께\n",
      "#혜장국\n",
      "#강남맛집\n",
      "#해장국\n",
      "#강남해장\n",
      "#강남역맛집\n",
      "#강남역맛집추천\n",
      "#신논현맛집\n",
      "#해장국맛집\n",
      "#차돌수육\n",
      "#한우수육\n",
      "#수육\n",
      "#신논현해장국\n",
      "#맛집추천\n",
      "#맛집소개\n",
      "#맛집\n",
      "#맛스타그램\n",
      "#맛폴레옹\n",
      "#해장국맛집추천\n",
      "#가로수길맛집\n",
      "#오봉집\n",
      "#미아맛집\n",
      "#수유맛집\n",
      "#서울맛집\n",
      "#서울여행\n",
      "#형제칼국수\n",
      "#강릉맛집\n",
      "#피웨인증맛집\n",
      "#벌집칼국수\n",
      "#금학칼국수\n",
      "#강릉여행\n",
      "#장칼국수\n",
      "#칼국수맛집\n",
      "#피그웨이브_강릉\n",
      "#코밥심_여의도\n",
      "#여의도의축복\n",
      "#아루히\n",
      "#아루히스시\n",
      "#진주집\n",
      "#피양옥여의도점\n",
      "#강남맛집\n",
      "#강남역맛집\n",
      "#강남역핫플\n",
      "#강남역가볼만한곳\n",
      "#강남역파스타\n",
      "#강남역술집\n",
      "#일상\n",
      "#맛스타그램\n",
      "#맛집\n",
      "#강남맛집\n",
      "#원조부안집\n",
      "#부안집\n",
      "#잠실새내맛집\n",
      "#잠실맛집\n",
      "#잠실데이트\n",
      "#한강공원\n",
      "#잠실역맛집\n",
      "#잠실새내역맛집\n",
      "#한강피크닉\n",
      "#거인통닭\n",
      "#부산거인통닭\n",
      "#부산치킨\n",
      "#깡통시장\n",
      "#부산깡통시장\n",
      "#깡통시장맛집\n",
      "#부평깡통시장\n",
      "#자갈치시장\n",
      "#자갈치시장맛집\n",
      "#부산맛집\n",
      "#부산여행\n",
      "#폭포수식당\n",
      "#서울근교여행\n",
      "#경기도맛집\n",
      "#양주맛집\n",
      "#백숙맛집\n",
      "#피그웨이브_양주\n",
      "#먹는행복\n",
      "#옷스타그램\n",
      "#장산맛집\n",
      "#상남동맛집\n",
      "#남포동맛집\n",
      "#강남맛집\n",
      "#인계동맛집\n",
      "#신사역맛집\n",
      "#아침밥상\n",
      "#셀피스타그램\n",
      "#부산맛집\n",
      "#일상\n",
      "#헬스\n",
      "#바다\n",
      "#여행\n",
      "#꽃스타그램\n",
      "#역삼동맛집\n",
      "#창원맛집\n",
      "#성산일출봉\n",
      "#애월맛집\n",
      "#성산맛집\n",
      "#황리단길맛집\n",
      "#강남맛집\n",
      "#강남역맛집\n",
      "#강남가볼만한곳\n",
      "#강남역파스타\n",
      "#강남핫플\n",
      "#강남술집\n",
      "#청담맛집\n",
      "#양재맛집\n",
      "#논현맛집\n",
      "#맛스타그램\n",
      "#맛집\n",
      "#인스타광고\n",
      "#강남맛집\n",
      "#컬쿤\n",
      "#컬처쿤스트\n",
      "#로하스칼프\n",
      "#에셈피\n",
      "#강남두피문신\n",
      "#여성헤어라인\n",
      "#탈모\n",
      "#탈모고민\n",
      "#여주두피문신\n",
      "#두피타투\n",
      "#헤어타투\n",
      "#헤어문신\n",
      "#강남역삼\n",
      "#강남맛집\n",
      "#강남\n",
      "#교대\n",
      "#맛집\n",
      "#강남맛집\n",
      "#교대맛집\n",
      "#술집\n",
      "#포차\n",
      "#데일리\n",
      "#내돈내산�\n",
      "#데이트\n",
      "#일상공유\n",
      "#먹스타그램�\n",
      "#돼지스타그램���\n",
      "#백화네부엌교대점\n",
      "#교대마차\n",
      "#와사비보쌈\n",
      "#오돌뼈주먹밥\n",
      "#참이슬후레쉬�\n",
      "#소주\n",
      "====================================================================================================\n",
      "총 소요시간: 164.7 초\n",
      "총 저장 건수: 15 건 \n",
      "파일 저장 경로: c:\\temp\\2021-07-14-11-26-21-인스타그램-강남맛집\\2021-07-14-11-26-21-강남맛집.txt\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]').click()\n",
    "\n",
    "# 자동 스크롤다운 함수\n",
    "def scroll_down(driver):\n",
    "  driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "  time.sleep(5)\n",
    "\n",
    "i = 1\n",
    "while (i <= real_cnt):\n",
    "      scroll_down(driver) \n",
    "      i += 1\n",
    "\n",
    "# Step 6. 전체 게시물의 원본 URL 추출하기\n",
    "item=[]\n",
    "count = 0\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "all = soup.find('article','KC1QD').find_all('a')\n",
    "\n",
    "for i in all:    \n",
    "    url = i['href']\n",
    "    item.append(url)  \n",
    "    count += 1\n",
    "    \n",
    "    if count == cnt :\n",
    "        break\n",
    "\n",
    "# 추출된 URL 사용하여 전체 URL 완성하기\n",
    "full_url=[]\n",
    "url_cnt = 0\n",
    "for x in range(0,len(item)) :\n",
    "    url_cnt += 1\n",
    "    url = 'https://www.instagram.com' +item[x]\n",
    "    full_url.append(url)\n",
    "\n",
    "#Step 7. 각 페이지별로 그림과 해쉬태그를 수집하기\n",
    "count = 1        # 추출 데이터 건수 세기\n",
    "hash_txt = []    # 해쉬 태그 저장 \n",
    "\n",
    "# 비트맵 이미지 아이콘을 위한 대체 딕셔너리를 만든다\n",
    "import sys\n",
    "bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "\n",
    "count = 0\n",
    "for c in range(0,len(full_url)) :\n",
    "    driver.get(full_url[c])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    f = open(f_name, 'a',encoding='UTF-8')\n",
    "        \n",
    "    # 해당 페이지의 해시태그 수집\n",
    "    tags = soup.find('div','EtaWk')\n",
    "    \n",
    "    try :\n",
    "        tags_1 = tags.find_all('a')\n",
    "    except :\n",
    "        pass\n",
    "    else :\n",
    "        for d in range(0, len(tags_1)) :\n",
    "            tags = tags_1[d].get_text()\n",
    "            tags_11 = tags.translate(bmp_map)\n",
    "            tags_2 = unicodedata.normalize('NFC', tags_11)\n",
    "            \n",
    "            for i in tags_2 :\n",
    "                if i[0:1]=='#' :\n",
    "                    hash_txt.append(tags_2)\n",
    "                    print(tags_2)\n",
    "                    f.write(\"\\n\" + str(tags_2))\n",
    "    f.close()\n",
    "    count += 1\n",
    "    \n",
    "#Step 7. 요약 정보 출력하기    \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *100)\n",
    "print(\"총 소요시간: %s 초\" %round(t_time,1))\n",
    "print(\"총 저장 건수: %s 건 \" %count)\n",
    "print(\"파일 저장 경로: %s\" %f_name)\n",
    "print(\"=\" *100)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
