{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5e1236",
   "metadata": {},
   "source": [
    "# 연습문제  \n",
    "레드/화이트 와인 구분 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3ba7a",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282929b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "white = pd.read_csv('../data/winequality-white.csv',sep=';')\n",
    "white['division'] = 0\n",
    "red = pd.read_csv('../data/winequality-red.csv',sep=';')\n",
    "red['division'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d230288",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e11d42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  division  \n",
       "0      9.4        5         1  \n",
       "1      9.8        5         1  \n",
       "2      9.8        5         1  \n",
       "3      9.8        6         1  \n",
       "4      9.4        5         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99eef288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  division  \n",
       "0      8.8        6         0  \n",
       "1      9.5        6         0  \n",
       "2     10.1        6         0  \n",
       "3      9.9        6         0  \n",
       "4      9.9        6         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bba13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.concat([red, white])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680628fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91fbf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  division  \n",
       "0      9.4        5         1  \n",
       "1      9.8        5         1  \n",
       "2      9.8        5         1  \n",
       "3      9.8        6         1  \n",
       "4      9.4        5         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da52559",
   "metadata": {},
   "source": [
    "## 데이터 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb695da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6497 entries, 0 to 4897\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6497 non-null   float64\n",
      " 1   volatile acidity      6497 non-null   float64\n",
      " 2   citric acid           6497 non-null   float64\n",
      " 3   residual sugar        6497 non-null   float64\n",
      " 4   chlorides             6497 non-null   float64\n",
      " 5   free sulfur dioxide   6497 non-null   float64\n",
      " 6   total sulfur dioxide  6497 non-null   float64\n",
      " 7   density               6497 non-null   float64\n",
      " 8   pH                    6497 non-null   float64\n",
      " 9   sulphates             6497 non-null   float64\n",
      " 10  alcohol               6497 non-null   float64\n",
      " 11  quality               6497 non-null   int64  \n",
      " 12  division              6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 710.6 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556cc9c7",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5219647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_data: (1300, 12)\n",
      "Shape of test_targets: (1300,)\n",
      "Shape of train_data: (4157, 12)\n",
      "Shape of train_targets: (4157,)\n",
      "Shape of val_data: (1040, 12)\n",
      "Shape of val_targets: (1040,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(wine.drop(['division'],axis=1))\n",
    "y = np.array(wine['division'])\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=100)\n",
    "\n",
    "print(\"Shape of test_data: {}\".format(test_data.shape))\n",
    "print(\"Shape of test_targets: {}\".format(test_targets.shape))\n",
    "\n",
    "train_data, val_data, train_targets, val_targets = train_test_split(train_data, \n",
    "                                                    train_targets, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=100)\n",
    "print(\"Shape of train_data: {}\".format(train_data.shape))\n",
    "print(\"Shape of train_targets: {}\".format(train_targets.shape))\n",
    "print(\"Shape of val_data: {}\".format(val_data.shape))\n",
    "print(\"Shape of val_targets: {}\".format(val_targets.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b7625",
   "metadata": {},
   "source": [
    "## 데이터 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b26e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf689322",
   "metadata": {},
   "source": [
    "## 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b55231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62db1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "42/42 [==============================] - 2s 11ms/step - loss: 0.5321 - binary_accuracy: 0.7575 - val_loss: 0.5088 - val_binary_accuracy: 0.7375\n",
      "Epoch 2/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4568 - binary_accuracy: 0.7597 - val_loss: 0.4391 - val_binary_accuracy: 0.7462\n",
      "Epoch 3/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3972 - binary_accuracy: 0.7881 - val_loss: 0.3832 - val_binary_accuracy: 0.8058\n",
      "Epoch 4/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8436 - val_loss: 0.3384 - val_binary_accuracy: 0.8654\n",
      "Epoch 5/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3099 - binary_accuracy: 0.8927 - val_loss: 0.3024 - val_binary_accuracy: 0.9048\n",
      "Epoch 6/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2784 - binary_accuracy: 0.9242 - val_loss: 0.2734 - val_binary_accuracy: 0.9317\n",
      "Epoch 7/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2527 - binary_accuracy: 0.9396 - val_loss: 0.2497 - val_binary_accuracy: 0.9462\n",
      "Epoch 8/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2315 - binary_accuracy: 0.9519 - val_loss: 0.2300 - val_binary_accuracy: 0.9510\n",
      "Epoch 9/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2138 - binary_accuracy: 0.9598 - val_loss: 0.2136 - val_binary_accuracy: 0.9538\n",
      "Epoch 10/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1988 - binary_accuracy: 0.9632 - val_loss: 0.1996 - val_binary_accuracy: 0.9606\n",
      "Epoch 11/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1860 - binary_accuracy: 0.9656 - val_loss: 0.1876 - val_binary_accuracy: 0.9596\n",
      "Epoch 12/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1750 - binary_accuracy: 0.9682 - val_loss: 0.1773 - val_binary_accuracy: 0.9644\n",
      "Epoch 13/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1654 - binary_accuracy: 0.9709 - val_loss: 0.1682 - val_binary_accuracy: 0.9663\n",
      "Epoch 14/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1569 - binary_accuracy: 0.9723 - val_loss: 0.1603 - val_binary_accuracy: 0.9673\n",
      "Epoch 15/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1494 - binary_accuracy: 0.9740 - val_loss: 0.1532 - val_binary_accuracy: 0.9673\n",
      "Epoch 16/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1427 - binary_accuracy: 0.9757 - val_loss: 0.1469 - val_binary_accuracy: 0.9692\n",
      "Epoch 17/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1367 - binary_accuracy: 0.9771 - val_loss: 0.1412 - val_binary_accuracy: 0.9721\n",
      "Epoch 18/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1313 - binary_accuracy: 0.9779 - val_loss: 0.1361 - val_binary_accuracy: 0.9721\n",
      "Epoch 19/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1264 - binary_accuracy: 0.9791 - val_loss: 0.1315 - val_binary_accuracy: 0.9721\n",
      "Epoch 20/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1220 - binary_accuracy: 0.9793 - val_loss: 0.1272 - val_binary_accuracy: 0.9731\n",
      "Epoch 21/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1179 - binary_accuracy: 0.9803 - val_loss: 0.1234 - val_binary_accuracy: 0.9750\n",
      "Epoch 22/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1141 - binary_accuracy: 0.9803 - val_loss: 0.1198 - val_binary_accuracy: 0.9760\n",
      "Epoch 23/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1107 - binary_accuracy: 0.9812 - val_loss: 0.1165 - val_binary_accuracy: 0.9760\n",
      "Epoch 24/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1075 - binary_accuracy: 0.9815 - val_loss: 0.1134 - val_binary_accuracy: 0.9769\n",
      "Epoch 25/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1045 - binary_accuracy: 0.9817 - val_loss: 0.1106 - val_binary_accuracy: 0.9779\n",
      "Epoch 26/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1017 - binary_accuracy: 0.9822 - val_loss: 0.1080 - val_binary_accuracy: 0.9798\n",
      "Epoch 27/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0991 - binary_accuracy: 0.9829 - val_loss: 0.1055 - val_binary_accuracy: 0.9788\n",
      "Epoch 28/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0967 - binary_accuracy: 0.9834 - val_loss: 0.1032 - val_binary_accuracy: 0.9788\n",
      "Epoch 29/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0945 - binary_accuracy: 0.9841 - val_loss: 0.1010 - val_binary_accuracy: 0.9788\n",
      "Epoch 30/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0923 - binary_accuracy: 0.9841 - val_loss: 0.0990 - val_binary_accuracy: 0.9788\n",
      "Epoch 31/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0903 - binary_accuracy: 0.9844 - val_loss: 0.0971 - val_binary_accuracy: 0.9788\n",
      "Epoch 32/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0884 - binary_accuracy: 0.9846 - val_loss: 0.0953 - val_binary_accuracy: 0.9788\n",
      "Epoch 33/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0867 - binary_accuracy: 0.9848 - val_loss: 0.0936 - val_binary_accuracy: 0.9798\n",
      "Epoch 34/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0850 - binary_accuracy: 0.9848 - val_loss: 0.0920 - val_binary_accuracy: 0.9808\n",
      "Epoch 35/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0834 - binary_accuracy: 0.9851 - val_loss: 0.0905 - val_binary_accuracy: 0.9808\n",
      "Epoch 36/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0818 - binary_accuracy: 0.9853 - val_loss: 0.0890 - val_binary_accuracy: 0.9817\n",
      "Epoch 37/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0804 - binary_accuracy: 0.9853 - val_loss: 0.0876 - val_binary_accuracy: 0.9817\n",
      "Epoch 38/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0790 - binary_accuracy: 0.9853 - val_loss: 0.0863 - val_binary_accuracy: 0.9827\n",
      "Epoch 39/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0777 - binary_accuracy: 0.9856 - val_loss: 0.0851 - val_binary_accuracy: 0.9827\n",
      "Epoch 40/250\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0765 - binary_accuracy: 0.9856 - val_loss: 0.0839 - val_binary_accuracy: 0.9827\n",
      "Epoch 41/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0753 - binary_accuracy: 0.9856 - val_loss: 0.0828 - val_binary_accuracy: 0.9827\n",
      "Epoch 42/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0741 - binary_accuracy: 0.9858 - val_loss: 0.0817 - val_binary_accuracy: 0.9827\n",
      "Epoch 43/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0730 - binary_accuracy: 0.9860 - val_loss: 0.0806 - val_binary_accuracy: 0.9827\n",
      "Epoch 44/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0720 - binary_accuracy: 0.9860 - val_loss: 0.0797 - val_binary_accuracy: 0.9846\n",
      "Epoch 45/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0710 - binary_accuracy: 0.9863 - val_loss: 0.0787 - val_binary_accuracy: 0.9856\n",
      "Epoch 46/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0700 - binary_accuracy: 0.9865 - val_loss: 0.0778 - val_binary_accuracy: 0.9856\n",
      "Epoch 47/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0691 - binary_accuracy: 0.9868 - val_loss: 0.0769 - val_binary_accuracy: 0.9856\n",
      "Epoch 48/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0682 - binary_accuracy: 0.9868 - val_loss: 0.0761 - val_binary_accuracy: 0.9856\n",
      "Epoch 49/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0673 - binary_accuracy: 0.9870 - val_loss: 0.0753 - val_binary_accuracy: 0.9865\n",
      "Epoch 50/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0665 - binary_accuracy: 0.9868 - val_loss: 0.0745 - val_binary_accuracy: 0.9865\n",
      "Epoch 51/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0657 - binary_accuracy: 0.9868 - val_loss: 0.0738 - val_binary_accuracy: 0.9875\n",
      "Epoch 52/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0649 - binary_accuracy: 0.9868 - val_loss: 0.0731 - val_binary_accuracy: 0.9875\n",
      "Epoch 53/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0642 - binary_accuracy: 0.9868 - val_loss: 0.0724 - val_binary_accuracy: 0.9875\n",
      "Epoch 54/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0635 - binary_accuracy: 0.9873 - val_loss: 0.0717 - val_binary_accuracy: 0.9875\n",
      "Epoch 55/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0628 - binary_accuracy: 0.9873 - val_loss: 0.0711 - val_binary_accuracy: 0.9885\n",
      "Epoch 56/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0621 - binary_accuracy: 0.9873 - val_loss: 0.0705 - val_binary_accuracy: 0.9885\n",
      "Epoch 57/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0615 - binary_accuracy: 0.9875 - val_loss: 0.0699 - val_binary_accuracy: 0.9885\n",
      "Epoch 58/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0608 - binary_accuracy: 0.9875 - val_loss: 0.0693 - val_binary_accuracy: 0.9885\n",
      "Epoch 59/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0602 - binary_accuracy: 0.9875 - val_loss: 0.0688 - val_binary_accuracy: 0.9885\n",
      "Epoch 60/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0596 - binary_accuracy: 0.9877 - val_loss: 0.0682 - val_binary_accuracy: 0.9885\n",
      "Epoch 61/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0591 - binary_accuracy: 0.9882 - val_loss: 0.0677 - val_binary_accuracy: 0.9885\n",
      "Epoch 62/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0585 - binary_accuracy: 0.9882 - val_loss: 0.0672 - val_binary_accuracy: 0.9885\n",
      "Epoch 63/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0580 - binary_accuracy: 0.9880 - val_loss: 0.0667 - val_binary_accuracy: 0.9885\n",
      "Epoch 64/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0575 - binary_accuracy: 0.9880 - val_loss: 0.0663 - val_binary_accuracy: 0.9885\n",
      "Epoch 65/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0570 - binary_accuracy: 0.9882 - val_loss: 0.0658 - val_binary_accuracy: 0.9885\n",
      "Epoch 66/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0565 - binary_accuracy: 0.9882 - val_loss: 0.0654 - val_binary_accuracy: 0.9885\n",
      "Epoch 67/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0560 - binary_accuracy: 0.9882 - val_loss: 0.0650 - val_binary_accuracy: 0.9885\n",
      "Epoch 68/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0555 - binary_accuracy: 0.9882 - val_loss: 0.0646 - val_binary_accuracy: 0.9885\n",
      "Epoch 69/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0551 - binary_accuracy: 0.9882 - val_loss: 0.0642 - val_binary_accuracy: 0.9885\n",
      "Epoch 70/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0546 - binary_accuracy: 0.9882 - val_loss: 0.0638 - val_binary_accuracy: 0.9885\n",
      "Epoch 71/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0542 - binary_accuracy: 0.9882 - val_loss: 0.0634 - val_binary_accuracy: 0.9885\n",
      "Epoch 72/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0538 - binary_accuracy: 0.9887 - val_loss: 0.0631 - val_binary_accuracy: 0.9885\n",
      "Epoch 73/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0534 - binary_accuracy: 0.9887 - val_loss: 0.0627 - val_binary_accuracy: 0.9885\n",
      "Epoch 74/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0530 - binary_accuracy: 0.9887 - val_loss: 0.0624 - val_binary_accuracy: 0.9885\n",
      "Epoch 75/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0526 - binary_accuracy: 0.9887 - val_loss: 0.0621 - val_binary_accuracy: 0.9885\n",
      "Epoch 76/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0523 - binary_accuracy: 0.9887 - val_loss: 0.0618 - val_binary_accuracy: 0.9885\n",
      "Epoch 77/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0519 - binary_accuracy: 0.9887 - val_loss: 0.0615 - val_binary_accuracy: 0.9885\n",
      "Epoch 78/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0515 - binary_accuracy: 0.9887 - val_loss: 0.0612 - val_binary_accuracy: 0.9885\n",
      "Epoch 79/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0512 - binary_accuracy: 0.9889 - val_loss: 0.0609 - val_binary_accuracy: 0.9885\n",
      "Epoch 80/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0509 - binary_accuracy: 0.9889 - val_loss: 0.0606 - val_binary_accuracy: 0.9885\n",
      "Epoch 81/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0505 - binary_accuracy: 0.9889 - val_loss: 0.0604 - val_binary_accuracy: 0.9885\n",
      "Epoch 82/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0502 - binary_accuracy: 0.9889 - val_loss: 0.0601 - val_binary_accuracy: 0.9885\n",
      "Epoch 83/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0499 - binary_accuracy: 0.9892 - val_loss: 0.0598 - val_binary_accuracy: 0.9885\n",
      "Epoch 84/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0496 - binary_accuracy: 0.9892 - val_loss: 0.0596 - val_binary_accuracy: 0.9885\n",
      "Epoch 85/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0493 - binary_accuracy: 0.9892 - val_loss: 0.0594 - val_binary_accuracy: 0.9885\n",
      "Epoch 86/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0490 - binary_accuracy: 0.9894 - val_loss: 0.0591 - val_binary_accuracy: 0.9885\n",
      "Epoch 87/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0487 - binary_accuracy: 0.9894 - val_loss: 0.0589 - val_binary_accuracy: 0.9885\n",
      "Epoch 88/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0484 - binary_accuracy: 0.9894 - val_loss: 0.0587 - val_binary_accuracy: 0.9885\n",
      "Epoch 89/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0482 - binary_accuracy: 0.9894 - val_loss: 0.0585 - val_binary_accuracy: 0.9885\n",
      "Epoch 90/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0479 - binary_accuracy: 0.9894 - val_loss: 0.0583 - val_binary_accuracy: 0.9885\n",
      "Epoch 91/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0476 - binary_accuracy: 0.9897 - val_loss: 0.0581 - val_binary_accuracy: 0.9885\n",
      "Epoch 92/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0474 - binary_accuracy: 0.9899 - val_loss: 0.0579 - val_binary_accuracy: 0.9885\n",
      "Epoch 93/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0471 - binary_accuracy: 0.9897 - val_loss: 0.0577 - val_binary_accuracy: 0.9885\n",
      "Epoch 94/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0469 - binary_accuracy: 0.9897 - val_loss: 0.0576 - val_binary_accuracy: 0.9885\n",
      "Epoch 95/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0466 - binary_accuracy: 0.9897 - val_loss: 0.0574 - val_binary_accuracy: 0.9885\n",
      "Epoch 96/250\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0464 - binary_accuracy: 0.9897 - val_loss: 0.0572 - val_binary_accuracy: 0.9885\n",
      "Epoch 97/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0462 - binary_accuracy: 0.9901 - val_loss: 0.0571 - val_binary_accuracy: 0.9885\n",
      "Epoch 98/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0460 - binary_accuracy: 0.9901 - val_loss: 0.0569 - val_binary_accuracy: 0.9885\n",
      "Epoch 99/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0457 - binary_accuracy: 0.9901 - val_loss: 0.0567 - val_binary_accuracy: 0.9885\n",
      "Epoch 100/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0455 - binary_accuracy: 0.9901 - val_loss: 0.0566 - val_binary_accuracy: 0.9885\n",
      "Epoch 101/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0453 - binary_accuracy: 0.9901 - val_loss: 0.0565 - val_binary_accuracy: 0.9885\n",
      "Epoch 102/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0451 - binary_accuracy: 0.9901 - val_loss: 0.0563 - val_binary_accuracy: 0.9885\n",
      "Epoch 103/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0449 - binary_accuracy: 0.9904 - val_loss: 0.0562 - val_binary_accuracy: 0.9885\n",
      "Epoch 104/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0447 - binary_accuracy: 0.9906 - val_loss: 0.0561 - val_binary_accuracy: 0.9885\n",
      "Epoch 105/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0445 - binary_accuracy: 0.9906 - val_loss: 0.0559 - val_binary_accuracy: 0.9885\n",
      "Epoch 106/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0443 - binary_accuracy: 0.9906 - val_loss: 0.0558 - val_binary_accuracy: 0.9885\n",
      "Epoch 107/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0441 - binary_accuracy: 0.9906 - val_loss: 0.0557 - val_binary_accuracy: 0.9885\n",
      "Epoch 108/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0440 - binary_accuracy: 0.9906 - val_loss: 0.0556 - val_binary_accuracy: 0.9885\n",
      "Epoch 109/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0438 - binary_accuracy: 0.9906 - val_loss: 0.0555 - val_binary_accuracy: 0.9885\n",
      "Epoch 110/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0436 - binary_accuracy: 0.9906 - val_loss: 0.0554 - val_binary_accuracy: 0.9894\n",
      "Epoch 111/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0434 - binary_accuracy: 0.9906 - val_loss: 0.0553 - val_binary_accuracy: 0.9894\n",
      "Epoch 112/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0433 - binary_accuracy: 0.9906 - val_loss: 0.0552 - val_binary_accuracy: 0.9894\n",
      "Epoch 113/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0431 - binary_accuracy: 0.9906 - val_loss: 0.0551 - val_binary_accuracy: 0.9894\n",
      "Epoch 114/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0429 - binary_accuracy: 0.9906 - val_loss: 0.0550 - val_binary_accuracy: 0.9894\n",
      "Epoch 115/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0428 - binary_accuracy: 0.9906 - val_loss: 0.0549 - val_binary_accuracy: 0.9894\n",
      "Epoch 116/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0426 - binary_accuracy: 0.9909 - val_loss: 0.0548 - val_binary_accuracy: 0.9894\n",
      "Epoch 117/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0425 - binary_accuracy: 0.9909 - val_loss: 0.0547 - val_binary_accuracy: 0.9894\n",
      "Epoch 118/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0423 - binary_accuracy: 0.9911 - val_loss: 0.0547 - val_binary_accuracy: 0.9894\n",
      "Epoch 119/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0422 - binary_accuracy: 0.9911 - val_loss: 0.0546 - val_binary_accuracy: 0.9894\n",
      "Epoch 120/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0420 - binary_accuracy: 0.9911 - val_loss: 0.0545 - val_binary_accuracy: 0.9894\n",
      "Epoch 121/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0419 - binary_accuracy: 0.9911 - val_loss: 0.0544 - val_binary_accuracy: 0.9894\n",
      "Epoch 122/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0418 - binary_accuracy: 0.9911 - val_loss: 0.0544 - val_binary_accuracy: 0.9894\n",
      "Epoch 123/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0416 - binary_accuracy: 0.9913 - val_loss: 0.0543 - val_binary_accuracy: 0.9894\n",
      "Epoch 124/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0415 - binary_accuracy: 0.9913 - val_loss: 0.0542 - val_binary_accuracy: 0.9894\n",
      "Epoch 125/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0414 - binary_accuracy: 0.9913 - val_loss: 0.0542 - val_binary_accuracy: 0.9894\n",
      "Epoch 126/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0412 - binary_accuracy: 0.9913 - val_loss: 0.0541 - val_binary_accuracy: 0.9894\n",
      "Epoch 127/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0411 - binary_accuracy: 0.9913 - val_loss: 0.0541 - val_binary_accuracy: 0.9894\n",
      "Epoch 128/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0410 - binary_accuracy: 0.9916 - val_loss: 0.0540 - val_binary_accuracy: 0.9894\n",
      "Epoch 129/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0409 - binary_accuracy: 0.9916 - val_loss: 0.0540 - val_binary_accuracy: 0.9894\n",
      "Epoch 130/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0407 - binary_accuracy: 0.9916 - val_loss: 0.0539 - val_binary_accuracy: 0.9894\n",
      "Epoch 131/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0406 - binary_accuracy: 0.9916 - val_loss: 0.0539 - val_binary_accuracy: 0.9894\n",
      "Epoch 132/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0405 - binary_accuracy: 0.9916 - val_loss: 0.0538 - val_binary_accuracy: 0.9894\n",
      "Epoch 133/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0404 - binary_accuracy: 0.9916 - val_loss: 0.0538 - val_binary_accuracy: 0.9894\n",
      "Epoch 134/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0403 - binary_accuracy: 0.9916 - val_loss: 0.0537 - val_binary_accuracy: 0.9894\n",
      "Epoch 135/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0402 - binary_accuracy: 0.9916 - val_loss: 0.0537 - val_binary_accuracy: 0.9894\n",
      "Epoch 136/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0401 - binary_accuracy: 0.9916 - val_loss: 0.0537 - val_binary_accuracy: 0.9894\n",
      "Epoch 137/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0400 - binary_accuracy: 0.9916 - val_loss: 0.0536 - val_binary_accuracy: 0.9894\n",
      "Epoch 138/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0398 - binary_accuracy: 0.9916 - val_loss: 0.0536 - val_binary_accuracy: 0.9894\n",
      "Epoch 139/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0397 - binary_accuracy: 0.9918 - val_loss: 0.0536 - val_binary_accuracy: 0.9894\n",
      "Epoch 140/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0396 - binary_accuracy: 0.9918 - val_loss: 0.0535 - val_binary_accuracy: 0.9904\n",
      "Epoch 141/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0395 - binary_accuracy: 0.9918 - val_loss: 0.0535 - val_binary_accuracy: 0.9904\n",
      "Epoch 142/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0394 - binary_accuracy: 0.9918 - val_loss: 0.0535 - val_binary_accuracy: 0.9904\n",
      "Epoch 143/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0394 - binary_accuracy: 0.9918 - val_loss: 0.0535 - val_binary_accuracy: 0.9904\n",
      "Epoch 144/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0393 - binary_accuracy: 0.9918 - val_loss: 0.0534 - val_binary_accuracy: 0.9904\n",
      "Epoch 145/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0392 - binary_accuracy: 0.9918 - val_loss: 0.0534 - val_binary_accuracy: 0.9904\n",
      "Epoch 146/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0391 - binary_accuracy: 0.9918 - val_loss: 0.0534 - val_binary_accuracy: 0.9904\n",
      "Epoch 147/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0390 - binary_accuracy: 0.9918 - val_loss: 0.0534 - val_binary_accuracy: 0.9904\n",
      "Epoch 148/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0389 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 149/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0388 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 150/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0387 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 151/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0386 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 152/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0386 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 153/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0385 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 154/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0384 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9904\n",
      "Epoch 155/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0383 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9904\n",
      "Epoch 156/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0382 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9904\n",
      "Epoch 157/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0382 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9904\n",
      "Epoch 158/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0381 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9904\n",
      "Epoch 159/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0380 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9904\n",
      "Epoch 160/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0379 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9904\n",
      "Epoch 161/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0379 - binary_accuracy: 0.9918 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 162/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0378 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 163/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0377 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 164/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0376 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 165/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0376 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 166/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0375 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 167/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0374 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 168/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0374 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 169/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0373 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 170/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0372 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 171/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0372 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 172/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0371 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 173/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0371 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 174/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0370 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 175/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0369 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 176/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0369 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 177/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0368 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 178/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0368 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 179/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0367 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 180/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0367 - binary_accuracy: 0.9921 - val_loss: 0.0532 - val_binary_accuracy: 0.9913\n",
      "Epoch 181/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0366 - binary_accuracy: 0.9921 - val_loss: 0.0533 - val_binary_accuracy: 0.9913\n",
      "Epoch 182/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0365 - binary_accuracy: 0.9921 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 183/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0365 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 184/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0364 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 185/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0364 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 186/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0363 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 187/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0363 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 188/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0362 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 189/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0362 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 190/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0361 - binary_accuracy: 0.9918 - val_loss: 0.0533 - val_binary_accuracy: 0.9923\n",
      "Epoch 191/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0361 - binary_accuracy: 0.9918 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 192/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0360 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 193/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0360 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 194/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0359 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 195/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0359 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 196/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0358 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 197/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0358 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 198/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0357 - binary_accuracy: 0.9921 - val_loss: 0.0534 - val_binary_accuracy: 0.9923\n",
      "Epoch 199/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0357 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9923\n",
      "Epoch 200/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0357 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9923\n",
      "Epoch 201/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0356 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9923\n",
      "Epoch 202/250\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0356 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9933\n",
      "Epoch 203/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0355 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9933\n",
      "Epoch 204/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0355 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9933\n",
      "Epoch 205/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0354 - binary_accuracy: 0.9921 - val_loss: 0.0535 - val_binary_accuracy: 0.9933\n",
      "Epoch 206/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0354 - binary_accuracy: 0.9921 - val_loss: 0.0536 - val_binary_accuracy: 0.9933\n",
      "Epoch 207/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0354 - binary_accuracy: 0.9921 - val_loss: 0.0536 - val_binary_accuracy: 0.9933\n",
      "Epoch 208/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0353 - binary_accuracy: 0.9921 - val_loss: 0.0536 - val_binary_accuracy: 0.9933\n",
      "Epoch 209/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0353 - binary_accuracy: 0.9921 - val_loss: 0.0536 - val_binary_accuracy: 0.9933\n",
      "Epoch 210/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0352 - binary_accuracy: 0.9925 - val_loss: 0.0536 - val_binary_accuracy: 0.9933\n",
      "Epoch 211/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0352 - binary_accuracy: 0.9928 - val_loss: 0.0536 - val_binary_accuracy: 0.9933\n",
      "Epoch 212/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0352 - binary_accuracy: 0.9928 - val_loss: 0.0537 - val_binary_accuracy: 0.9933\n",
      "Epoch 213/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0351 - binary_accuracy: 0.9928 - val_loss: 0.0537 - val_binary_accuracy: 0.9933\n",
      "Epoch 214/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0351 - binary_accuracy: 0.9928 - val_loss: 0.0537 - val_binary_accuracy: 0.9933\n",
      "Epoch 215/250\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0351 - binary_accuracy: 0.9930 - val_loss: 0.0537 - val_binary_accuracy: 0.9933\n",
      "Epoch 216/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0350 - binary_accuracy: 0.9930 - val_loss: 0.0537 - val_binary_accuracy: 0.9933\n",
      "Epoch 217/250\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0350 - binary_accuracy: 0.9930 - val_loss: 0.0537 - val_binary_accuracy: 0.9942\n",
      "Epoch 218/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0349 - binary_accuracy: 0.9930 - val_loss: 0.0538 - val_binary_accuracy: 0.9942\n",
      "Epoch 219/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0349 - binary_accuracy: 0.9930 - val_loss: 0.0538 - val_binary_accuracy: 0.9942\n",
      "Epoch 220/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0349 - binary_accuracy: 0.9930 - val_loss: 0.0538 - val_binary_accuracy: 0.9942\n",
      "Epoch 221/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0348 - binary_accuracy: 0.9930 - val_loss: 0.0538 - val_binary_accuracy: 0.9942\n",
      "Epoch 222/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0348 - binary_accuracy: 0.9930 - val_loss: 0.0538 - val_binary_accuracy: 0.9942\n",
      "Epoch 223/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0348 - binary_accuracy: 0.9930 - val_loss: 0.0538 - val_binary_accuracy: 0.9942\n",
      "Epoch 224/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0347 - binary_accuracy: 0.9930 - val_loss: 0.0539 - val_binary_accuracy: 0.9942\n",
      "Epoch 225/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0347 - binary_accuracy: 0.9930 - val_loss: 0.0539 - val_binary_accuracy: 0.9942\n",
      "Epoch 226/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0347 - binary_accuracy: 0.9930 - val_loss: 0.0539 - val_binary_accuracy: 0.9942\n",
      "Epoch 227/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0346 - binary_accuracy: 0.9930 - val_loss: 0.0539 - val_binary_accuracy: 0.9942\n",
      "Epoch 228/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0346 - binary_accuracy: 0.9930 - val_loss: 0.0539 - val_binary_accuracy: 0.9942\n",
      "Epoch 229/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0346 - binary_accuracy: 0.9930 - val_loss: 0.0540 - val_binary_accuracy: 0.9942\n",
      "Epoch 230/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0345 - binary_accuracy: 0.9930 - val_loss: 0.0540 - val_binary_accuracy: 0.9942\n",
      "Epoch 231/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0345 - binary_accuracy: 0.9930 - val_loss: 0.0540 - val_binary_accuracy: 0.9942\n",
      "Epoch 232/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0345 - binary_accuracy: 0.9933 - val_loss: 0.0540 - val_binary_accuracy: 0.9942\n",
      "Epoch 233/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0344 - binary_accuracy: 0.9933 - val_loss: 0.0540 - val_binary_accuracy: 0.9942\n",
      "Epoch 234/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0344 - binary_accuracy: 0.9933 - val_loss: 0.0541 - val_binary_accuracy: 0.9942\n",
      "Epoch 235/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0344 - binary_accuracy: 0.9933 - val_loss: 0.0541 - val_binary_accuracy: 0.9942\n",
      "Epoch 236/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0343 - binary_accuracy: 0.9933 - val_loss: 0.0541 - val_binary_accuracy: 0.9942\n",
      "Epoch 237/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0343 - binary_accuracy: 0.9933 - val_loss: 0.0541 - val_binary_accuracy: 0.9942\n",
      "Epoch 238/250\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0343 - binary_accuracy: 0.9933 - val_loss: 0.0541 - val_binary_accuracy: 0.9942\n",
      "Epoch 239/250\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0342 - binary_accuracy: 0.9933 - val_loss: 0.0541 - val_binary_accuracy: 0.9942\n",
      "Epoch 240/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0342 - binary_accuracy: 0.9933 - val_loss: 0.0542 - val_binary_accuracy: 0.9942\n",
      "Epoch 241/250\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0342 - binary_accuracy: 0.9933 - val_loss: 0.0542 - val_binary_accuracy: 0.9942\n",
      "Epoch 242/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0342 - binary_accuracy: 0.9933 - val_loss: 0.0542 - val_binary_accuracy: 0.9942\n",
      "Epoch 243/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0341 - binary_accuracy: 0.9933 - val_loss: 0.0542 - val_binary_accuracy: 0.9942\n",
      "Epoch 244/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0341 - binary_accuracy: 0.9933 - val_loss: 0.0542 - val_binary_accuracy: 0.9942\n",
      "Epoch 245/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0341 - binary_accuracy: 0.9933 - val_loss: 0.0543 - val_binary_accuracy: 0.9942\n",
      "Epoch 246/250\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0340 - binary_accuracy: 0.9933 - val_loss: 0.0543 - val_binary_accuracy: 0.9942\n",
      "Epoch 247/250\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0340 - binary_accuracy: 0.9933 - val_loss: 0.0543 - val_binary_accuracy: 0.9942\n",
      "Epoch 248/250\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0340 - binary_accuracy: 0.9933 - val_loss: 0.0543 - val_binary_accuracy: 0.9942\n",
      "Epoch 249/250\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0340 - binary_accuracy: 0.9933 - val_loss: 0.0543 - val_binary_accuracy: 0.9942\n",
      "Epoch 250/250\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0339 - binary_accuracy: 0.9933 - val_loss: 0.0544 - val_binary_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1806a2465b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = train_data.shape[1],activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate = 0.01)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "model.fit(train_data, train_targets, epochs=250, batch_size = 100, shuffle=False, validation_data=(val_data,val_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79da74",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdee046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0352 - binary_accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03515171632170677, 0.9915384650230408]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
