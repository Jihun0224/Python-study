{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62083efc",
   "metadata": {},
   "source": [
    "# 웹 크롤링  \n",
    "1. 사람이 파이썬 언어로 Selenium 에게 특정 웹 페이지를 크롤링하라고 명령한다.\n",
    "2. Selenium은 소스코드에 지정된 Web Driver를 실행하여 웹 페이지에 접속한다.\n",
    "3. 접속한 웹 페이지를 HTML 소스코드 형태로 현재 크롤링을 실행하는 컴퓨터로 가져온다.\n",
    "4. 수집된 HTML 전체 코드에서 Beautiful Soup를 사용하여 원하는 부분만 골라낸다.\n",
    "5. 골라낸 데이터를 원하는 형식의 파일로 저장한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3541ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromedriver_autoinstaller\n",
    "chromedriver_autoinstaller.install()\n",
    "from selenium import webdriver\n",
    "driver= webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0daf57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 해양자원\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# riss.kr 에서 특정 키워드로 논문 / 학술 자료 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "import time          \n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "#query_txt = '해양자원,도시재생'\n",
    "print(\"\\n\")\n",
    "\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "url = 'http://www.riss.kr/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "# element 정보를 가져 올 때 id/name/xpath\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "#element = driver.find_by_name(\"query\")\n",
    "#element = driver.find_by_xpath('//*[@id=\"query\"]')\n",
    "#xpath안에 \"\"가 있으므로 밖에 ''를 사용할 것!!\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click()\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff9f64",
   "metadata": {},
   "source": [
    "연습 문제로 실력 굳히기\n",
    "1. 네이버 사이트의 검색창에 “서진수 빅데이터” 키워드를 입력한 후 검색을 실행하도록 코드를\n",
    "작성하세요\n",
    "2. 다음 사이트의 검색창에 “서진수 빅데이터” 키워드를 입력한 후 검색을 실행하도록 코드를 작\n",
    "성하세요.\n",
    "3. 구글 사이트의 검색창에 “서진수 빅데이터” 키워드를 입력한 후 검색을 실행하도록 코드를 작\n",
    "성하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c85ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.naver.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click()\n",
    "element.send_keys(\"서진수 빅데이터\")\n",
    "element.send_keys(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5cce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.daum.net/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "element = driver.find_element_by_id(\"q\")\n",
    "driver.find_element_by_id(\"q\").click()\n",
    "element.send_keys(\"서진수 빅데이터\")\n",
    "element.send_keys(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11722b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.google.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "element = driver.find_element_by_name(\"q\")\n",
    "driver.find_element_by_name(\"q\").click()\n",
    "element.send_keys(\"서진수 빅데이터\")\n",
    "element.send_keys(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350d575",
   "metadata": {},
   "source": [
    "연습문제  \n",
    "경남대학교 홈페이지에서 오른쪽 상단의 돋보기 버튼을 클릭한 후 장학금 키워드로 게시물을 검색하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1cecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'https://www.kyungnam.ac.kr/ko/7979/subview.do'\n",
    "a= driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/ul/li[1]/a\").click()\n",
    "element = driver.find_element_by_id(\"top-search\")\n",
    "driver.find_element_by_id(\"top-search\").click()\n",
    "element.send_keys(\"장학금\")\n",
    "element.send_keys(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df6657",
   "metadata": {},
   "source": [
    "## BeautifulSoup 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbeddddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과를 저장할 파일명을 쓰세요(예: c:\\temp\\riss.txt): ./riss.txt\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys \n",
    "\n",
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.riss.kr/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click()\n",
    "element.send_keys(\"전염병\")\n",
    "element.send_keys(\"\\n\")\n",
    "#find_elemnet_by_link: 하이퍼링크로 이동, 글자는 text\n",
    "driver.find_element_by_link_text(\"학위논문\").click()\n",
    "time.sleep(2)\n",
    "html_1 = driver.page_source\n",
    "soup = BeautifulSoup(html_1,'html.parser')\n",
    "\n",
    "soup_1 = soup.select('div.srchResultListW > ul > li')\n",
    "for i in soup_1:\n",
    "    print(i.get_text().replace('\\n',\" \").strip())\n",
    "    print('\\n')\n",
    "f_name = input('결과를 저장할 파일명을 쓰세요(예: c:\\\\temp\\\\riss.txt): ')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in soup_1:\n",
    "    print(i.get_text().replace(\"\\n\",\" \"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cde51b",
   "metadata": {},
   "source": [
    "## 연습문제  \n",
    "1. 네이버 사이트에서 '서진수 빅데이터'로 검색 한 후 '뉴스' 카테고리를 선택하여 조회된 기사들을 수집하여 txt형식으로 저장  \n",
    "2. 다음 사이트에서 '서진수 빅데이터'로 검색 한 후 '뉴스' 카테고리를 선택하여 조회된 기사들을 수집하여 txt형식으로 저장  \n",
    "3. 한국관광공사의 대한민국 구석구석 사이트에서 '여름여행' 키워드로 검색 한 후 화면 오른쪽의 '어제의 인기 검색어' 목록을 수집하여 txt형식으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12830aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과를 저장할 파일명을 쓰세요(예: c:\\temp\\riss.txt): ./naver.txt\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.naver.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click()\n",
    "element.send_keys(\"서진수 빅데이터\")\n",
    "element.send_keys(\"\\n\")\n",
    "driver.find_element_by_link_text(\"뉴스\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "html_1 = driver.page_source\n",
    "soup = BeautifulSoup(html_1,'html.parser')\n",
    "soup_1 = soup.find('div','group_news').find_all('li')\n",
    "\n",
    "f_name = input('결과를 저장할 파일명을 쓰세요(예: c:\\\\temp\\\\riss.txt): ')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in soup_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c108b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 \n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.daum.net/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "element = driver.find_element_by_id(\"q\")\n",
    "driver.find_element_by_id(\"q\").click()\n",
    "element.send_keys(\"서진수 빅데이터\")\n",
    "element.send_keys(\"\\n\")\n",
    "driver.find_element_by_link_text(\"뉴스\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "html_1 = driver.page_source\n",
    "soup = BeautifulSoup(html_1,'html.parser')\n",
    "soup_1 = soup.find('div','cont_divider').find('ul',class_='list_news').find_all('li')\n",
    "\n",
    "f_name = input('결과를 저장할 파일명을 쓰세요(예: c:\\\\temp\\\\riss.txt): ')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in soup_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ee5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "chrome_path = \"c:/temp/chromedriver_91/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'https://korean.visitkorea.or.kr'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#driver.maximize-window() //반응형 웹일때 사용 => 창크기 최대로\n",
    "\n",
    "element = driver.find_element_by_xpath('//*[@id=\"inp_search\"]')\n",
    "driver.find_element_by_xpath('//*[@id=\"inp_search\"]').click()\n",
    "element.send_keys(\"여름여행\")\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(2)\n",
    "html_1 = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46da1679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 여름여행\n",
      "2 경기도\n",
      "3 통영\n",
      "4 강원도\n",
      "5 가을여행\n",
      "6 부산\n",
      "7 제주도\n",
      "8 계곡\n",
      "9 여수\n",
      "10 경주\n",
      "결과를 저장할 파일명을 쓰세요(예: c:\\temp\\riss.txt): ./rank.txt\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 ./rank.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "soup = BeautifulSoup(html_1,'html.parser')\n",
    "title = soup.find('div','box_rightType3')('em')\n",
    "rank = soup.find('div','box_rightType3')('span')\n",
    "for i in range(len(rank)):\n",
    "    print(rank[i].text,title[i].text)\n",
    "    \n",
    "f_name = input('결과를 저장할 파일명을 쓰세요(예: c:\\\\temp\\\\riss.txt): ')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in range(len(rank)):\n",
    "    print(rank[i].text,\"위:\",title[i].text)\n",
    "\n",
    "file.close()\n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
