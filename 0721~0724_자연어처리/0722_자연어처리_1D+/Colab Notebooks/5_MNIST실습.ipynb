{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_MNIST실습.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOoSXVh5Orp23Zr2FYg+rcq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZTWiWRNzWHn","executionInfo":{"status":"ok","timestamp":1627043587396,"user_tz":-540,"elapsed":701,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"2601bc97-272f-45e8-a780-c5fb56644d26"},"source":["%tensorflow_version 2.x\n","from tensorflow.keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","print(train_images.shape)\n","print(test_images.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","(10000, 28, 28)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FYti4oOd3A8X"},"source":["## 출력 설정"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNaDf5eH03YQ","executionInfo":{"status":"ok","timestamp":1627043589574,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"0e2bdb02-3d1c-47e0-9ed4-7e14b7031063"},"source":["print(test_images[1])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0\n","    5  20  20  37 150 150 150 147  10   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143\n","  166 253 253 253 253 253 253 253 123   0]\n"," [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253\n","  253 253 249 247 247 169 117 117  57   0]\n"," [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155\n","  123 123  41   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4s3nYnl3EvH","executionInfo":{"status":"ok","timestamp":1627043592128,"user_tz":-540,"elapsed":581,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"8fcef4ac-877c-48f7-da80-7ec7d4fc05be"},"source":["print(type(test_images))\n","import numpy as np\n","#linewidth : 한 줄에 출력될 문자의 최대 수\n","#set_printoptions: 부동 소수점, 어레이, 그리고 다른 NumPy 객체가 표시되는 방식을 설정합니다.\n","np.set_printoptions(linewidth=np.inf)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0b9aplwz3TID"},"source":["## 재출력"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVUKyhyR3PdI","executionInfo":{"status":"ok","timestamp":1627043594446,"user_tz":-540,"elapsed":734,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"b115204a-406e-4488-d042-84a4cc4bea48"},"source":["print(test_images[1])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n"," [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n"," [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"pyHI1Lf43bEp","executionInfo":{"status":"ok","timestamp":1627043595711,"user_tz":-540,"elapsed":323,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"8bd7b2b6-80a0-4d18-958a-0f670c2b72d1"},"source":["import matplotlib.pyplot as plt\n","plt.imshow(test_images[1])"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f0d4ff78650>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"S-oU38EF31wq"},"source":["## Label 정보 출력"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AbEjP0M3ruk","executionInfo":{"status":"ok","timestamp":1627043597614,"user_tz":-540,"elapsed":274,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"12a61dea-e562-4316-8658-7de413b15a26"},"source":["# train, test 데이터 모두 label을 가지고 있으며, 0~9의 숫자임\n","print(train_labels)\n","print(test_labels)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[5 0 4 ... 5 6 8]\n","[7 2 1 ... 4 5 6]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EEKDv83H4Bs9"},"source":["## Layer 쌓기"]},{"cell_type":"markdown","metadata":{"id":"I8Uc7tznOzJE"},"source":["##  tf.keras.layers.Dense\n","- units : 출력 값의 크기\n","- activation : 활성화 함수\n","- use_bias : 편향(b)을 사용할지 여부\n","- kernel_initializer : 가중치(W) 초기화 함수\n","- bias_iniotializer : 편향 초기화 함수\n","- kernel_regularizer : 가중치 정규화 방법\n","- bias_regularizer : 편향 정규화 방법\n","- activity_regularizer : 출력 값 정규화 방법\n","- kernel_constraint : 가중치에 적용되는 부가적인 제약 함수\n","- bias_constraint : 편향에 적용되는 부가적인 제약 함수"]},{"cell_type":"markdown","metadata":{"id":"_OYbcclgPYIK"},"source":["## relu  \n","특징:  0 이하의 값은 다음 레이어에 전달하지 않음. 0이상의 값은 그대로 출력\n","\n","사용처: CNN을 학습시킬 때 많이 사용\n","\n","한계점: 한번 0 활성화 값을 다음 레이어에 전달하면 이후의 뉴런들의 출력값이 모두 0이 되는 현상이 발생, 이를 dying ReLU라 부름  \n","이러한 한계점을 개선하기 위해 음수 출력 값을 소량이나마 다음 레이어에 전달하는 방식으로 개선한 활성화 함수들이 등장"]},{"cell_type":"markdown","metadata":{"id":"XflM0qS3R4CO"},"source":["![image](https://user-images.githubusercontent.com/59672592/126779901-d225e1c2-ac5d-4e5b-8cd5-d5fe41e60ba5.png)\n"]},{"cell_type":"code","metadata":{"id":"207nojnG37Fk","executionInfo":{"status":"ok","timestamp":1627043601723,"user_tz":-540,"elapsed":658,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}}},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","model = models.Sequential()\n","# 은닉층 설정\n","# 처음에는 입력 shape을 설정한다. 3차원 데이터를 2차원으로 변형할 것이다. input_shape=(특성의 수, 샘플의 수)\n","# 단, 샘플의 개수는 몇 개가 올지 알 수 없으므로 비워둬야 한다\n","model.add(layers.Dense(256,activation='relu',input_shape = (28*28,)))\n","\n","# 출력층 설정. 숫자의 종류가 10개이므로, 10개의 유닛을 갖는 출력층을 설정한다\n","# 10개 각각에 대한 확률정보 출력. Softmax 층은 확률 점수를 출력한다\n","model.add(layers.Dense(10,activation='softmax'))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xcJi7VIb-Kvj"},"source":["## Complie model"]},{"cell_type":"code","metadata":{"id":"vXlCwgKO4SwX","executionInfo":{"status":"ok","timestamp":1627043603401,"user_tz":-540,"elapsed":492,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}}},"source":["# loss: loss function. 훈련 데이터에서 신경망의 성능을 측정하는 손실 함수\n","# optimizer: 입력된 데이터와 손실 함수를 기반으로 가중치를 업데이트하는 방법\n","# metrics: 훈련과 테스트 과정을 모니터링할 지표. ‘acc’라고도 씀\n","#categorical_crossentropy는 다중 분류 손실함수로 one-hot encoding 클래스를 사용한다. \n","#따라서 출력값이 one-hot encoding된 결과로 나오고 정답(label)과 비교하며 학습을 진행하거나 \n","#정확도를 알아내기 위해서는 정답(label)도 one-hot encoding된 형태여야 한다\n","\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQSSAvfmAwIl"},"source":["## 전처리 전"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3votncZ_suz","executionInfo":{"status":"ok","timestamp":1627043605322,"user_tz":-540,"elapsed":259,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"98081f98-2753-4e18-f49d-22c38831d5d7"},"source":["print(test_images[1,])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n"," [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n"," [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n"," [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"00tWtptgAyNZ"},"source":["## 데이터 변환"]},{"cell_type":"code","metadata":{"id":"P2bqkkUaABqZ","executionInfo":{"status":"ok","timestamp":1627043607263,"user_tz":-540,"elapsed":310,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}}},"source":["train_images = train_images.reshape((60000, 28*28))\n","train_images = train_images.astype('float32')/255\n","test_images = test_images.reshape((10000, 28*28))\n","test_images = test_images.astype('float32')/255\n","# reshape 함수를 이용해 데이터를 (60000, 784) 크기로 변환하고, \n","# 각 값을 255로 나누되, type을 소수점을 받는 float32 형으로 맞춤"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ef-g0k6Azd1"},"source":["## 전처리 후"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6BcASYFAfwG","executionInfo":{"status":"ok","timestamp":1627043609371,"user_tz":-540,"elapsed":734,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"7f959133-8593-4866-e106-aab516a5f63b"},"source":["np.set_printoptions(linewidth=310)\n","print(test_images[1])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.45490196 0.49019608 0.67058825 1.         1.         0.5882353  0.3647059  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.6627451  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.85490197 0.11764706 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.6627451  0.99215686 0.99215686 0.99215686 0.8352941  0.5568628  0.6901961  0.99215686 0.99215686 0.47843137 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.20392157 0.98039216 0.99215686 0.8235294  0.1254902  0.04705882 0.         0.02352941 0.80784315 0.99215686 0.54901963 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.3019608  0.9843137  0.8235294  0.09803922 0.         0.         0.         0.47843137 0.972549   0.99215686 0.25490198 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.12156863 0.07058824 0.         0.         0.         0.         0.81960785 0.99215686 0.99215686 0.25490198 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.45882353 0.96862745 0.99215686 0.7764706  0.03921569 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.29803923 0.96862745 0.99215686 0.90588236 0.24705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.5019608  0.99215686 0.99215686 0.5647059  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.6901961  0.9647059  0.99215686 0.62352943 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.09803922 0.91764706 0.99215686 0.9137255  0.13725491 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.7764706  0.99215686 0.99215686 0.5529412  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.30588236 0.972549   0.99215686 0.7411765  0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.07450981 0.78431374 0.99215686 0.99215686 0.5529412  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.5254902  0.99215686 0.99215686 0.6784314  0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.972549   0.99215686 0.99215686 0.09803922 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.972549   0.99215686 0.99215686 0.16862746 0.07843138 0.07843138 0.07843138 0.07843138 0.01960784 0.         0.01960784 0.07843138 0.07843138 0.14509805 0.5882353  0.5882353  0.5882353  0.5764706  0.03921569 0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.972549   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.65882355 0.56078434 0.6509804  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.48235294 0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.68235296 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9764706  0.96862745 0.96862745 0.6627451  0.45882353 0.45882353 0.22352941 0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.4627451  0.48235294 0.48235294 0.48235294 0.6509804  0.99215686 0.99215686 0.99215686 0.60784316 0.48235294 0.48235294 0.16078432 0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A81-a-4UBQTb"},"source":["## 종속변수를 범주형을 변환"]},{"cell_type":"code","metadata":{"id":"E7JCJevRAudm","executionInfo":{"status":"ok","timestamp":1627043612052,"user_tz":-540,"elapsed":419,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}}},"source":["from tensorflow.keras.utils import to_categorical\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wFW__oqKBXcY"},"source":["## 데이터 학습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOjb_4KBBPyb","executionInfo":{"status":"ok","timestamp":1627044585195,"user_tz":-540,"elapsed":24942,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"c65412a3-0914-4c7f-8a53-93f7038f716a"},"source":["# fit 메소드를 이용하여 모델을 훈련시킴\n","# train 데이터와 그의 label, 반복횟수 및 1번에 훈련할 데이터의 양(batch size)을 결정함\n","# 메모리 한계와 속도 저하 문제로 한 번에 전체 데이터를 학습하지는 않는다\n","# 일반적으로 8~512개의 데이터를 한 번에 학습시킨다\n","# 손실점수는 낮아지고, 정확도는 높아짐\n","# 훈련데이터에 대한 최종 정확도 98.9%\n","model.fit(train_images, train_labels, epochs=10, batch_size=128)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9986\n","Epoch 2/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.9990\n","Epoch 3/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9992\n","Epoch 4/10\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0027 - accuracy: 0.9994\n","Epoch 5/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9994\n","Epoch 6/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9996\n","Epoch 7/10\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0016 - accuracy: 0.9997\n","Epoch 8/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 9/10\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0011 - accuracy: 0.9998\n","Epoch 10/10\n","469/469 [==============================] - 3s 5ms/step - loss: 8.9590e-04 - accuracy: 0.9998\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f0d492b95d0>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"7k0pR-abFuih"},"source":["## 예측"]},{"cell_type":"code","metadata":{"id":"eb4vWXxNBcwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627044606184,"user_tz":-540,"elapsed":617,"user":{"displayName":"Jihun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLj6kvTiZpive_fnNuLhAt_1OcCOQ1gM7J0wY1=s64","userId":"05483927178716651768"}},"outputId":"98eb1165-006d-4111-bbc4-5a89337f2ca9"},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print('test_acc:', test_acc)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9810\n","test_acc: 0.9810000061988831\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yKLurhDwEXL1"},"source":[""],"execution_count":null,"outputs":[]}]}